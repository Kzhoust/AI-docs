# 端到端的深度学习

(翻译：饶正锋, Nov 2018)



### 47 端到端学习的兴起(rise)

假设你要开发一个系统，对用户评论进行分析，自动识别用户喜欢或不喜欢某个商品。例如，你想识别下面的用户评价是非常正面的：
​    This is a great mop!
下面的评价是非常负面的：
​    This mop is low quality--I regret buying it.

识别正面或负面评价的问题，就是情感分析。为了构建一个这样的系统，你可能需要构建一个由两个组件组成的"流水线"(pipeline):
1.parser:对文本进行标记，识别文本中最重要的词语。例如，标记所有的名词和形容词:
​    This is a great [Adjective] mop [Noun] !
(parser其实可以给出更丰富的标记信息，但在这里这个简单的例子就足够了)
2.情感分类器:将标记的文本作为输入，预测整个文本的情感倾向。parser的标记能起很大作用：给形容词更高权重，算法能快速追踪像“great,”这样的重要词语，忽略不重要的词语，如“this.”

我们可以把这个"pipeline"及它的两个组件画成下图：

![](/home/raozhengfeng/Downloads/111111111111.png)

最近有个趋势是，用单个的算法来取代pipeline系统。对于这个任务，端到端的学习算法可以用原文“This is a great mop!”作为输入,直接识别出情感：

![](/home/raozhengfeng/Downloads/111111111112.png)

​	神经网络被广泛应用于端到端系统中，术语“端到端”是指学习算法直接从输入到期望的输出，例如，学习算法直接将系统的"输入端"和"输出端"连接起来。

***译者注:***

> *端到端指尽量省去中间步骤，从问题的输入直接得到问题的输出，中间的过程都交给模型来学习、拟合。*
> *通常来说，在机器学习方面提端到端，只是指机器学习的算法部分，而那些确定性的预处理过程也可以不算在端到端的里面。*
>
> *分了多个步骤对于人来说可解释性更强了，但强行指定多个步骤的结合方式，肯定会损失一些信息。端到端模型通常希望把由人指定的中间步骤，也用机器学习替代，让数据来决定如何让两个步骤的信息直接结合起来，而不是转为人能看懂的显式中间层。*
> *端到端的好处就是只要维护一个模型的输入输出就够了，不用考虑中间结果的一些问题，通常效果更好，效率也更高。最好的解决一类具体问题，通常端到端的思路会比较好。*
>
> *https://www.zhihu.com/question/264358398/answer/280773231*

> *相对于深度学习，**传统机器学习**的流程往往由多个独立的模块组成，比如在一个典型的自然语言处理（Natural Language Processing）问题中，包括分词、词性标注、句法分析、语义分析等多个独立步骤，每个步骤是一个独立的任务，其结果的好坏会影响到下一步骤，从而影响整个训练的结果，这是非端到端的。*
>
> *而**深度学习**模型在训练过程中，从输入端（输入数据）到输出端会得到一个预测结果，与真实结果相比较会得到一个误差，这个误差会在模型中的每一层传递（反向传播），每一层的表示都会根据这个误差来做调整，直到模型收敛或达到预期的效果才结束，这是端到端的。*
>
> *两者相比，端到端的学习省去了在每一个独立学习任务执行之前所做的数据标注，为样本做标注的代价是昂贵的、易出错的。*
>
> ![](/home/raozhengfeng/Downloads/20180822005359757.png)
>
> *https://blog.csdn.net/ViatorSun/article/details/81880679*

> **不能说进行了数据预处理就不算是端到端**，比如图像送入卷积神经网络之前一般都要缩放到固定的尺寸(也可以通过池化等方式变换到固定尺寸)，但是你预处理之后的结果还是一个图像，并不是你最终需要的分类结果；所以，从你预处理之后的数据到你的结果还是端到端的。
>
> *再比如，要对一段文本进行情感分类；送入模型之前一般也要进行分词和word2vec，也算是预处理的过程，但是后面的特征学习和分类也是端到端的。*
>
> *https://www.zhihu.com/question/264358398/answer/282574210*



在数据很充足的一些任务中，端到端的系统被证明非常成功。但他们并非在所有情况下都是一个好的选择，接下来几章将会给出更多的例子，告诉你什么时候应该或不应该使用他们。



### 48 更多端到端学习的例子

假设你要开发个语音识别系统，可能需要开发下面３个组件：

![](/home/raozhengfeng/Downloads/111111111113.png)

这些组件按如下流程工作：
1.提取特征：抽取人工定义的一些特征，比如MFCC(Mel-frequency
cepstrum coefficients,梅尔频率倒谱系数,是一种在自动语音和说话人识别中广泛使用的特征),它是用来捕捉讲话中的内容，同时丢弃不相关的属性，比如音高（pitch）。
（tips:声音“三要素”：
​    响度loudness:又称声强或音量，它表示的是声音能量的强弱程度，主要取决于声波振幅的大小
​    音高pitch:也称音调，表示人耳对声音调子高低的主观感受。
​    音色timbre:又称音品，由声音波形的谐波频谱和包络决定。
​    https://blog.csdn.net/junllee/article/details/7217435）
2.音素(Phoneme)识别：有些语言学家将声音的基本单位称为"音素",例如"keep"中的"k"和“cake”中的"c"有相同的音素。本系统尝试识别语音片段中的音素。
3.最终识别:将识别好的音素序列，串到一起输出为文本(transcript).

作为对比，端到端系统可以输入语音片段，然后直接输出transcript.

![](/home/raozhengfeng/Downloads/111111111114.png)



目前为止，我们只讲了完全线性的机器学习"pipelines":输出依次从一个步骤到下一个步骤。pipelines完全可以更复杂，比如下面是一个自动驾驶的架构：

![](/home/raozhengfeng/Downloads/111111111115.png)

它有三个组件：一个通过摄像头检测其他车辆；一个检测行人；最后一个组件规划路径，防止撞到行人或者车辆。

并非pipeline中的所有组件都需要学习，例如论文“robot motion planning”有大量的算法来规划汽车最终的运动路径，很多算法都不涉及到学习。

与之相反，端到端的方法可能尝试读取传感器数据，直接输出转向。

![](/home/raozhengfeng/Downloads/111111111116.png)

虽然端到端的学习取得了很大成功，但它并不总是最好的方法。例如，端到端语音识别系统很好，但我怀疑它在自动驾驶中的效果。接下来几章解释原因。



### 49 端到端学习的利弊

看一下我们前面讲的语音识别pipeline:

![](/home/raozhengfeng/Downloads/111111111117.png)

这里面很多组件都是"人工"实现的：
​    1)MFCC是一系列人工设计的音频特征，虽然它们对输入的音频进行了合理的抽取，但也可能把一些信息给丢弃了，减少了输入信号。
​    2)音素是语言学家发明的，它们是语音的一种不完美的表示。在某种程度上，音素是一个很差的近似表示，强制算法使用音素表示会限制语音识别系统的性能。

虽然这些人工实现的组件限制了系统的性能，但是它们也有一些好处：
​    1)MFCC特征足够健壮(robust)，对某些不影响语音内容的属性来说，例如音高。所以，他们帮助简化了学习算法要解决的问题。
​    2)在某种程度上，音素是语音的一种合理表示，他们也可以帮助学习算法理解基本的声音组成部分，进而改进系统性能。

通常情况下，人工组件越多能让语音识别系统需要学习的数据越少，由MFCC和音素从数据中所捕获的人工知识(经验)可以为我们的算法提供知识。特别是在数据不够的情况下，这些知识很有用。

接下来看看端到端的系统：

![](/home/raozhengfeng/Downloads/111111111118.png)

这个系统没有人工知识。所以，如果训练集很小，它很可能比人工实现的pipeline要差。
然而，如果训练集很大，它就不会被MFCC或音素这些人工特征的不足所限制。如果学习算法是个大容量的神经网络，并且经过足够多的数据进行训练，它有潜力可以做到很好，而且可能达到最有错误率(optimal error rate)。

端到端的学习可以做的很好，如果“两端”－－输入端和输出端都有大量的标记好的数据。在这个例子中，我们需要一个包含很多（音频、文本）标签对的数据集。如果没有这样的数据，使用端到端的学习就要特别注意了。

如果你在处理训练集特别小的机器学习问题，大部分算法知识就需要人来提供了，比如人工实现的一些组件。

如果你选择不使用端到端的系统，你就得定义你的pipelie中的每个步骤，以及他们怎么组合到一起。下面几章，我们会给出一些建议告诉你如何设计pipelines。



### 50 选择pipeline组件：数据可获取性(availability)

在构建非端到端的pipeline系统时，怎么为pipeline选择好的组件？如何设计pipeline将会极大的影响整个系统的性能，还有个因素是你是否能为每个组件收集到足够的训练数据。

举个例子，下面的自动驾驶架构：

![](/home/raozhengfeng/Downloads/111111111119.png)

你可以使用机器学习来检测车辆与行人。并不难获得相关的训练数据：好多计算机视觉数据集都有大量标记好车辆和行人的数据；你也可以使用众包的形式来获得更大的数据集。这种方式获取检测车辆和行人组件的训练数据相对容易点。

相反，下面纯端到端的方法：

![](/home/raozhengfeng/Downloads/1111111111110.png)

要训练这个系统，我们需要一个很大的数据集（图像、转向）。让人开着车到处转然后记录他们的转向数据，显然是非常耗时和昂贵的。要覆盖所有可能的驾驶场景，你得准备一个特殊装备的车队，并且不停的路测。这让端到端的系统变得非常难训练。获取标记好的车辆和行人数据集显然容易多了。

特别是，如果能获得大量数据训练pipeline中的“即时(intermediate)模块”(比如车辆或行人检测器)，那么你可以考虑由多个步骤组成的pipeline。这种架构会很好，因为你可以使用所有可以获取的数据来训练即时模块。

在可以获取更多的端到端数据之前，我相信非端到端方法更有前途：它的架构更贴近(match)我们我们能获取到的数据。



### 51 选择pipeline组件：任务简单性(Task simplicity)

除了数据可获取性，在选择pipeline组建时你应该考虑的第二个因素是：单个组件解决问题有多简单？你应该选择那些易于构建或学习的组件。但组件“易于”学习是什么意思？

![](/home/raozhengfeng/Downloads/1111111111111.png)



看下下面这些机器学习任务，难度递增：

1. 对图片进行分类，检查图片是否过度曝光（就像上图）
2. 对图片进行分类，检查图片是室内拍的还是室外
3. 对图片进行分类，检查图片里面是否有猫
4. 对图片进行分类，检查图片里是否有黑白相间的猫
5. 对图片进行分类，检查图片里是否有暹罗猫（某个特殊品种的猫）

上面都是对图片进行二分类的任务：你输入一张图片，输出０或１。但是对神经网络来说，前面的任务看起来更"简单"，你可以使用少数几个训练样本就能学到。

关于任务是简单还是困难，目前机器学习并没有一个正式的定义。随着深度学习和多层神经网络的兴起，如果一个任务能通过较少的计算步骤（对应浅层神经网络）搞定，我们就说它是“简单”的；如果需要更多的计算步骤（对应深度神经网络），就是“困难”的。但这些都是非正式的定义。

*（信息论中有一个Kolmogorov Complexity,认为一个函数的复杂度是实现功能的最短的程序的长度，但是这种理论在AI中应用较少。）*



如果你能将一项复杂的任务，拆分成简单的子任务，然后为每一个子任务编码，你就是在为算法提供先验知识，能让任务学习的更高效。

![](/home/raozhengfeng/Downloads/1111111111112.png)



假设你要构建一个暹罗猫识别器。这是纯端到端架构：

![](/home/raozhengfeng/Downloads/1111111111113.png)

作为对比，你也可以使用下面两步来构建一个pipeline:

![](/home/raozhengfeng/Downloads/1111111111114.png)

第一步(cat detector)检测图像中的所有猫。

![](/home/raozhengfeng/Downloads/1111111111115.png)

第二步将检测到的所有猫的图片都裁剪出来(每次一只)，丢给猫种类分类器，最后如果检测是暹罗猫就输出１。

![](/home/raozhengfeng/Downloads/1111111111116.png)

与只通过0/1的标签数据来训练一个纯端到端的分类器相比，pipeline中的两个组件－－猫检测器和猫种类分类器看起来都要简单的多，而且需要的数据也少得多。

*（如果你熟悉目标检测算法，就会知道他们不仅学到了图像的0/1标签，还有包围盒子作为训练数据的一部分。）*

最后举个例子，再看看自动驾驶的pipeline:

![](/home/raozhengfeng/Downloads/1111111111117.png)

通过使用pipeline,你可以告诉算法，进行驾驶有３个关键步骤：(1)检测车辆　(2)检测行人 (3)规划路径。每一步都是一个相对简单的功能－－可以通过更少的数据来学到，与纯端到端的学习相比。

总结下，在选择pipeline中的组件时，尝试构建一个每个组件都相对“简单”，进而能从适量的数据中学习到的pipeline。



### 52 直接学习更丰富的输出

图像分类算法输入图像x,输出一个表示图像类别的整数。那么算法能输出一个句子来描述图像吗？

例如：

x  =　![](/home/raozhengfeng/Downloads/1111111111118.png)

y  = “A yellow bus driving down a road with green trees and green grass in the background.”

传统的监督学习方法会学习到一个函数 h :   X  → Y , y通常是一个实数。例如：

![1542792321418](/home/raozhengfeng/.config/Typora/typora-user-images/1542792321418.png)

端到端深度学习中最令人兴奋的一个进展是，可以让我们直接学习到比数字更复杂的y。在上面的给图像打字幕的示例中，你可以使用神经网络输入图像(x)，然后直接输出字幕(y)。

下面是更多的例子：![1542792566302](/home/raozhengfeng/.config/Typora/typora-user-images/1542792566302.png)

深度学习中这个趋势在加速发展：当你有正确的标记对(输出,输出)时，端到端的学习可以输出句子、图像、音频或其他远比数字丰富的多的输出。

